{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example study and method comparisons--GB1_2016\n",
    "GB1_2016 has combintorially measured all the possible mutations and been studied extensively in the previous literature. Here, we use GB1_2016 as an example to explore many different possible settings in ODBO and collect the corresponding results. We will walk through this notebook with detailed comments.\n",
    "To use this notebook, please change the global control varibles and read the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import odbo\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global control varibles\n",
    "This section describe the parameters used for three different datasets. We also have a detailed walkthrough for other datasets with less explorations in experimental settings in the seperated notebook. We recommend to checkout the [ODBO_for_different_datasets.ipynb](./ODBO_for_different_datasets.ipynb) instead.\n",
    "We note that we didn't do extensive hyperparameter tuning, so other values can work and might even work better.\n",
    "Values used in the data collection is listed in the comments. Due to different randomness for different device, the results might differ slightly from the results we obtain using local computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment settings \n",
    "dataset_name ='GB1_2016'\n",
    "random_seed = 9 #Random seed for the trial\n",
    "search_iter = 50 #Number of new observations, GB1_2014=100, BRCA1=50, avGFP_2016=50\n",
    "# Initialization method protocol\n",
    "update_method='independent'#find round 0 experiments to initiate BO. For the datasets with few changes in the sequences, 'correlate' mode is recommended. \n",
    "allow_abundance=True #If we allow the top scoring experiments to take abundance of a mutation in different sites into account.\n",
    "# Featurization settings\n",
    "method=['Avg','Max','Avg','Max'] #switching order for feature spaces to overcome local maxima in one certain representation\n",
    "mode='independent' #Feature computing mode. \n",
    "# Adaptive search space predicted by XGBOD model (Prescreening step)\n",
    "threshold = 0.05 #Use 0.05 of as threshold.\n",
    "# BO method settings (Optimization step)\n",
    "BO_method = 'ODBO_TuRBO' #Must be 'ODBO_BO' or 'ODBO_TuRBO' or 'BO' or 'TuRBO'\n",
    "gp_method='robust_regression' #Must be 'gp_regression' or 'robust_regression'\n",
    "acqfn = 'ei'\n",
    "tr_length = [3.2] #Trust region length, used in the TuRBO. \n",
    "batch_size = 1 #Number of new oberservations provided by BO. We found 1 is the most cost-effective experimentally\n",
    "failure_tolerance =10 #Number of failure iterations to change TR length in TuRBO\n",
    "save_files = False #Save files or not\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data initalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "np.random.seed(random_seed)\n",
    "data_test = pd.read_csv('../datasets/GB1_2016_149361.csv', sep=',')\n",
    "name_pre, Y_test = np.array(data_test['AACombo']), np.array(data_test['Fitness'])\n",
    "shuffle_order = np.arange(len(Y_test))\n",
    "np.random.shuffle(shuffle_order[1:])\n",
    "name_pre[1:], Y_test[1:] = name_pre[shuffle_order[1:]], Y_test[shuffle_order[1:]]\n",
    "name = odbo.utils.code_to_array(name_pre)\n",
    "#Load the preselected indices using a certain shuffling order. Control Round 0 experiments to be the same for different trials\n",
    "if os.path.isfile('sele_experiment_GB1_2016.npy') == True:\n",
    "    name_sele = np.load('sele_experiment_GB1_2016.npy')\n",
    "    Y_train = np.load('sele_fitness_GB1_2016.npy')\n",
    "else:\n",
    "    # Let each site has 20 AA codes at least show up twice \n",
    "    sele_indices = odbo.initialization.initial_design(name, least_occurance=2*np.ones(name.shape[1]),allow_abundance=allow_abundance, update_method=update_method,verbose = True)\n",
    "    # Initial experiments are selected to be name_sele with fitness of Y_sele\n",
    "    name_sele, Y_train = name[sele_indices, :], Y_test[sele_indices]\n",
    "print('Selected initial experiments no. is ', len(Y_train))\n",
    "print('Select max Y: ', Y_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization and find the adaptive search space model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "threshold = 0.05\n",
    "feature_model = odbo.featurization.MassiveFeatureTransform(raw_vars=name_sele, Y=Y_train, method = method[0], mode=mode)\n",
    "X_train = feature_model.transform(name_sele)\n",
    "X_test = feature_model.transform(name)\n",
    "\n",
    "def prescreening(X_train, Y_train, X_test, threshold):\n",
    "    # Get outliers or inliers using the threshold\n",
    "    labels_train = odbo.prescreening.sp_label(X_train, Y_train, thres=threshold)\n",
    "    # Find the XGBOD adaptive search space model\n",
    "    pre_model = odbo.prescreening.XGBOD(eval_metric = 'error', random_state = random_seed)\n",
    "    pre_model.fit(X_train, labels_train)\n",
    "    # Predict the entire search space to get the adapt search space\n",
    "    pred_test_labels = pre_model.predict(X_test)\n",
    "    sele_id_test = list(np.where(pred_test_labels == 0)[0])\n",
    "    return pre_model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat search data\n",
    "l, failure_count = 0, 0 #l is the current iteration, failure_count controls when to switch to another featurization\n",
    "X_train_sele, Y_train_sele = torch.tensor(X_train), torch.tensor(Y_train.reshape(len(Y_train),1))\n",
    "name_sele_temp = name_sele\n",
    "if BO_method == 'ODBO_TuRBO' or BO_method == 'TuRBO':\n",
    "    state = odbo.turbo.TurboState(dim=X_train_sele.shape[1], batch_size=batch_size, length=tr_length, n_trust_regions=len(tr_length), failure_tolerance = failure_tolerance)\n",
    "    state.best_value = Y_train_sele.max()\n",
    "\n",
    "## Run BO experiment with robust regression or directly gp\n",
    "\n",
    "while l < search_iter:\n",
    "    threshold = 0.05\n",
    "    # Switch different representations if one representation fails in \n",
    "    if BO_method == 'ODBO_BO' or BO_method == 'ODBO_TuRBO':\n",
    "        pre_model = prescreening(X_train_sele, Y_train_sele, X_test, threshold)\n",
    "        pred_test_labels = pre_model.predict(X_test)\n",
    "        sele_id_test_new = list(np.where(pred_test_labels == 0)[0])  \n",
    "        counter = 0\n",
    "        while len(sele_id_test_new) == 0:\n",
    "            counter = counter + 1\n",
    "            pre_model = prescreening(X_train_sele, Y_train_sele, X_test, threshold/2/counter)\n",
    "            pred_test_labels = pre_model.predict(X_test)\n",
    "            sele_id_test_new = list(np.where(pred_test_labels == 0)[0])            \n",
    "        sele_id_test = sele_id_test_new\n",
    "    else:\n",
    "        sele_id_test = np.arange(len(Y_test.ravel()))\n",
    "    print(\"Adapt space size, Entire space size: \", len(sele_id_test), name.shape[0])\n",
    "    \n",
    "    search_name_sele= name[sele_id_test, :]\n",
    "    X_test_sele, Y_test_sele = torch.tensor(X_test[sele_id_test, :]), torch.tensor(Y_test[sele_id_test].reshape(len(sele_id_test),1))\n",
    "    \n",
    "    print(\"Iter: \", l, \"Current Max: \", Y_train_sele.max().detach().numpy(), \"Test max: \", Y_test_sele.max().detach().numpy())\n",
    "    # Run optimization using different methods    \n",
    "    if BO_method == 'ODBO_BO' or BO_method == 'BO':\n",
    "        X_next, acq_value, next_exp_id = odbo.bo_design(X=X_train_sele, Y=Y_train_sele, X_pending=X_test_sele, gp_method=gp_method, batch_size=batch_size, acqfn=acqfn)\n",
    "    elif BO_method == 'ODBO_TuRBO' or BO_method == 'TuRBO':\n",
    "        X_next, acq_value, raw_next_exp_id = odbo.turbo_design(state=state, X=X_train_sele, Y=Y_train_sele, X_pending=X_test_sele, n_trust_regions=len(tr_length), batch_size=batch_size, gp_method=gp_method, acqfn=acqfn)\n",
    "        Y_next_m = torch.zeros((len(tr_length), batch_size, 1), device=Y_train_sele.device, dtype=Y_train_sele.dtype)\n",
    "        next_exp_id = []  \n",
    "        for i in range(batch_size):\n",
    "            next_exp_id_m = raw_next_exp_id[:, i]\n",
    "            Y_next_m[:, i, 0], idtoadd = Y_test_sele[next_exp_id_m].reshape(len(tr_length)), next_exp_id_m[np.argmax(Y_test_sele[next_exp_id_m])]\n",
    "            next_exp_id.append(idtoadd)\n",
    "    # Update the newly find experimental value to the current training set, and remove that point from test set\n",
    "    Y_train_sele = torch.cat([Y_train_sele, Y_test_sele[next_exp_id]])\n",
    "    name_sele_temp = np.concatenate((name_sele_temp, search_name_sele[next_exp_id]))\n",
    "    remove_id = np.array(sele_id_test)[next_exp_id]\n",
    "    ids_keep = list(np.delete(range(name.shape[0]), remove_id))\n",
    "    X_test,Y_test,name = X_test[ids_keep], Y_test[ids_keep], name[ids_keep]\n",
    "    print(\"Newly added value: \", Y_train_sele[-batch_size:].detach().numpy(), ''.join(name_sele_temp[-1, :]))\n",
    "    if BO_method == 'ODBO_TuRBO'or BO_method == 'TuRBO':\n",
    "        # Update the TuRBO state with the newly added Y values\n",
    "        state = odbo.turbo.update_state(state=state, Y_next=Y_next_m)\n",
    "    if Y_train_sele[-batch_size:].detach().numpy().max() > Y_train_sele[:-batch_size].max():\n",
    "        failure_count = 0\n",
    "        feature_model = odbo.featurization.MassiveFeatureTransform(raw_vars=name_sele_temp, Y=Y_train_sele.detach().numpy(), method=method[1], mode=mode)\n",
    "    else:\n",
    "        failure_count = failure_count + 1\n",
    "        if failure_count >= 3:\n",
    "            feature_model = odbo.featurization.MassiveFeatureTransform(raw_vars=name_sele_temp, Y=Y_train_sele.detach().numpy(), method=method[2], mode=mode)\n",
    "        else:\n",
    "            feature_model = odbo.featurization.MassiveFeatureTransform(raw_vars=name_sele_temp, Y=Y_train_sele.detach().numpy(), method=method[3], mode=mode)\n",
    "    X_train_sele = torch.tensor(feature_model.transform(name_sele_temp))\n",
    "    X_test = feature_model.transform(name)\n",
    "\n",
    "    l = l + 1\n",
    "\n",
    "# Save the BO results. Note we save all the observations including the Round 0 ones\n",
    "if save_files:\n",
    "    if acqfn == 'ei':\n",
    "        if gp_method == 'robust_regression':\n",
    "            np.save('results/{}/{}_{}_update_XGBOD_RobustGP_batch{}_{}.npy'.format(dataset_name, dataset_name, BO_method, batch_size, random_seed), Y_train_sele)\n",
    "        elif gp_method == 'gp_regression':\n",
    "            np.save('results/{}/{}_{}_update_XGBOD_GP_batch{}_{}.npy'.format(dataset_name, dataset_name, BO_method, batch_size, random_seed), Y_train_sele)\n",
    "    else:\n",
    "        if gp_method == 'robust_regression':\n",
    "            np.save('results/{}/{}_{}_update_XGBOD_RobustGP_batch{}_{}_{}.npy'.format(dataset_name, dataset_name, BO_method, batch_size, acqfn, random_seed), Y_train_sele)\n",
    "        elif gp_method == 'gp_regression':\n",
    "            np.save('results/{}/{}_{}_update_XGBOD_GP_batch{}_{}_{}.npy'.format(dataset_name, dataset_name, BO_method, batch_size, acqfn, random_seed), Y_train_sele)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
