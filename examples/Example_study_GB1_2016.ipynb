{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example study and method comparisons--GB1_2016\n",
    "GB1_2016 has combintorially measured all the possible mutations and been studied extensively in the previous literature. Here, we use GB1_2016 as an example to explore many different possible settings in ODBO and collect the corresponding results. We will walk through this notebook with detailed comments.\n",
    "To use this notebook, please change the global control varibles and read the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import odbo\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global control varibles\n",
    "This section describe the parameters used for GB1_2016 dataset. We also have a detailed walkthrough for other datasets with less explorations in experimental settings in the seperated notebook. We recommend to checkout the [ODBO_for_different_datasets.ipynb](./ODBO_for_different_datasets.ipynb) instead.\n",
    "We note that we didn't do extensive hyperparameter tuning, so other values can work and might even work better.\n",
    "Values used in the data collection is listed in the comments. Due to different randomness for different device, the results might differ slightly from the results we obtain using local computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment settings \n",
    "dataset_name ='GB1_2016'\n",
    "random_seed = 0 #Random seed for the trial\n",
    "search_iter = 50 #Number of new observations, GB1_2014=100, BRCA1=50, avGFP_2016=50\n",
    "# Initialization method protocol\n",
    "update_method='independent'#find round 0 experiments to initiate BO. For the datasets with few changes in the sequences, 'correlate' mode is recommended. \n",
    "allow_abundance=True #If we allow the top scoring experiments to take abundance of a mutation in different sites into account.\n",
    "# Featurization settings\n",
    "method=['Avg','Max','Avg','Max'] #switching order for feature spaces to overcome local maxima in one certain representation\n",
    "mode='independent' #Feature computing mode. \n",
    "# Adaptive search space predicted by XGBOD model (Prescreening step)\n",
    "threshold = 0.05 #Use 0.05 of as threshold.\n",
    "cMat_plot = True #Plot the confusion matrix to check the accuracy of search space prescreening or not\n",
    "# BO method settings (Optimization step)\n",
    "BO_method = 'ODBO_TuRBO' #Must be 'ODBO_BO' or 'ODBO_TuRBO' or 'BO' or 'TuRBO'\n",
    "gp_method='robust_regression' #Must be 'gp_regression' or 'robust_regression'\n",
    "acqfn = 'ts'\n",
    "tr_length = [3.2] #Trust region length, used in the TuRBO. \n",
    "batch_size = 1 #Number of new oberservations provided by BO. We found 1 is the most cost-effective experimentally\n",
    "failure_tolerance =10 #Number of failure iterations to change TR length in TuRBO\n",
    "save_files = True #Save files or not\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data initalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "np.random.seed(random_seed)\n",
    "data_test = pd.read_csv('../datasets/GB1_2016_149361.csv', sep=',')\n",
    "name_pre, Y_test = np.array(data_test['AACombo']), np.array(data_test['Fitness'])\n",
    "shuffle_order = np.arange(len(Y_test))\n",
    "np.random.shuffle(shuffle_order[1:])\n",
    "name_pre[1:], Y_test[1:] = name_pre[shuffle_order[1:]], Y_test[shuffle_order[1:]]\n",
    "name = odbo.utils.code_to_array(name_pre)\n",
    "#Load the preselected indices using a certain shuffling order. Control Round 0 experiments to be the same for different trials\n",
    "if os.path.isfile('sele_experiment_GB1_2016.npy') == True:\n",
    "    name_sele = np.load('sele_experiment_GB1_2016.npy')\n",
    "    Y_train = np.load('sele_fitness_GB1_2016.npy')\n",
    "else:\n",
    "    # Let each site has 20 AA codes at least show up twice \n",
    "    sele_indices = odbo.initialization.initial_design(name, least_occurance=2*np.ones(name.shape[1]),allow_abundance=allow_abundance, update_method=update_method,verbose = True)\n",
    "    # Initial experiments are selected to be name_sele with fitness of Y_sele\n",
    "    name_sele, Y_train = name[sele_indices, :], Y_test[sele_indices]\n",
    "print('Selected initial experiments no. is ', len(Y_train))\n",
    "print('Select max Y: ', Y_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurization and find the adaptive search space model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using MassiveFeatureTransform method to transform features. (Since GB1 2016 mutates all the sites)\n",
    "feature_model = odbo.featurization.MassiveFeatureTransform(raw_vars=name_sele, Y=Y_train, method = method[0], mode=mode)\n",
    "X_train = feature_model.transform(name_sele)\n",
    "X_test = feature_model.transform(name)\n",
    "if BO_method == 'ODBO_BO' or BO_method == 'ODBO_TuRBO':\n",
    "    # Get outliers or inliers using the threshold\n",
    "    labels_train = odbo.prescreening.sp_label(X_train, Y_train, thres=threshold)\n",
    "    # Find the XGBOD adaptive search space model\n",
    "    pre_model = odbo.prescreening.XGBOD(eval_metric = 'error', random_state = random_seed)\n",
    "    pre_model.fit(X_train, labels_train)\n",
    "    # Predict the entire search space to get the adapt search space\n",
    "    labels_test = odbo.prescreening.sp_label(X_test, Y_test, thres=threshold)\n",
    "    pred_test_labels = pre_model.predict(X_test)\n",
    "    sele_id_test = list(np.where(pred_test_labels == 0)[0])\n",
    "    # Plot the confusion matrix to check the accuracy of search space prescreening\n",
    "    if cMat_plot:\n",
    "        out_outlier, in_outlier, out_inlier, in_inlier = odbo.plot.plot_cm(labels_test, pred_test_labels, Y_test)\n",
    "        print(\"Correct ratio: {0:.3%}\".format((len(out_outlier)+len(in_inlier))/len(labels_test)))\n",
    "        print(\"FN ratio: {0:.3%}\".format(len(out_inlier)/len(out_inlier)+len(out_outlier)))\n",
    "        print(\"FP ratio: {0:.3%}\".format(len(in_outlier)/len(in_outlier)+len(in_inlier)))\n",
    "else:\n",
    "    sele_id_test = np.arange(len(Y_test.ravel()))\n",
    "print(\"Adapt space size, Entire space size: \", len(sele_id_test), name.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creat search data\n",
    "X_train_sele, Y_train_sele = torch.tensor(X_train), torch.tensor(Y_train.reshape(len(Y_train),1))\n",
    "search_name_sele, name_sele_temp = name[sele_id_test, :], name_sele\n",
    "X_test_sele, Y_test_sele = torch.tensor(X_test[sele_id_test, :]), torch.tensor(Y_test[sele_id_test].reshape(len(sele_id_test),1))\n",
    "\n",
    "## Run BO experiment with robust regression or directly gp\n",
    "l, failure_count = 0, 0 #l is the current iteration, failure_count controls when to switch to another featurization\n",
    "if BO_method == 'ODBO_TuRBO' or BO_method == 'TuRBO':\n",
    "    state = odbo.turbo.TurboState(dim=X_train_sele.shape[1], batch_size=batch_size, length=tr_length, n_trust_regions=len(tr_length), failure_tolerance = failure_tolerance)\n",
    "    state.best_value = Y_train_sele.max()\n",
    "\n",
    "while l < search_iter:\n",
    "    print(\"Iter: \", l, \"Current Max: \", Y_train_sele.max().detach().numpy(), \"Test max: \", Y_test_sele.max().detach().numpy())\n",
    "    # Run optimization using different methods    \n",
    "    if BO_method == 'ODBO_BO' or BO_method == 'BO':\n",
    "        X_next, acq_value, next_exp_id = odbo.bo_design(X=X_train_sele, Y=Y_train_sele, X_pending=X_test_sele, gp_method=gp_method, batch_size=batch_size, acqfn=acqfn)\n",
    "    elif BO_method == 'ODBO_TuRBO' or BO_method == 'TuRBO':\n",
    "        X_next, acq_value, raw_next_exp_id = odbo.turbo_design(state=state, X=X_train_sele, Y=Y_train_sele, X_pending=X_test_sele, n_trust_regions=len(tr_length), batch_size=batch_size, gp_method=gp_method, acqfn=acqfn)\n",
    "        Y_next_m = torch.zeros((len(tr_length), batch_size, 1), device=Y_train_sele.device, dtype=Y_train_sele.dtype)\n",
    "        next_exp_id = []  \n",
    "        for i in range(batch_size):\n",
    "            next_exp_id_m = raw_next_exp_id[:, i]\n",
    "            Y_next_m[:, i, 0], idtoadd = Y_test_sele[next_exp_id_m].reshape(len(tr_length)), next_exp_id_m[np.argmax(Y_test_sele[next_exp_id_m])]\n",
    "            next_exp_id.append(idtoadd)\n",
    "    # Update the newly find experimental value to the current training set, and remove that point from test set\n",
    "    Y_train_sele = torch.cat([Y_train_sele, Y_test_sele[next_exp_id]])\n",
    "    ids_keep = list(np.delete(range(Y_test_sele.shape[0]), next_exp_id))\n",
    "    Y_test_sele = Y_test_sele[ids_keep]\n",
    "    name_sele_temp = np.concatenate((name_sele_temp, search_name_sele[next_exp_id]))\n",
    "    search_name_sele = search_name_sele[ids_keep]\n",
    "    print(\"Newly added value: \", Y_train_sele[-batch_size:].detach().numpy(), ''.join(name_sele_temp[-1, :]))\n",
    "    if BO_method == 'ODBO_TuRBO'or BO_method == 'TuRBO':\n",
    "        # Update the TuRBO state with the newly added Y values\n",
    "        state = odbo.turbo.update_state(state=state, Y_next=Y_next_m)\n",
    "\n",
    "    # Switch different representations if one representation fails in \n",
    "    if Y_train_sele[-batch_size:].detach().numpy().max() > Y_train_sele[:-batch_size].max():\n",
    "        failure_count = 0\n",
    "        feature_model = odbo.featurization.MassiveFeatureTransform(raw_vars=name_sele_temp, \n",
    "                                                                Y=Y_train_sele.detach().numpy(), method=method[1], mode=mode)\n",
    "    else:\n",
    "        failure_count = failure_count + 1\n",
    "        if failure_count >= 3:\n",
    "            feature_model = odbo.featurization.MassiveFeatureTransform(raw_vars=name_sele_temp, \n",
    "                                                                    Y=Y_train_sele.detach().numpy(), method=method[2], mode=mode)\n",
    "        else:\n",
    "            feature_model = odbo.featurization.MassiveFeatureTransform(raw_vars=name_sele_temp, \n",
    "                                                                    Y=Y_train_sele.detach().numpy(), method=method[3], mode=mode)\n",
    "    X_test_sele= torch.tensor(feature_model.transform(search_name_sele))\n",
    "    X_train_sele = torch.tensor(feature_model.transform(name_sele_temp))\n",
    "    l = l + 1\n",
    "\n",
    "# Save the BO results. Note we save all the observations including the Round 0 ones\n",
    "if save_files:\n",
    "    if acqfn == 'ei':\n",
    "        if gp_method == 'robust_regression':\n",
    "            np.save('results/{}/{}_{}_RobustGP_batch{}_{}.npy'.format(dataset_name, dataset_name, BO_method, batch_size, random_seed), Y_train_sele)\n",
    "        elif gp_method == 'gp_regression':\n",
    "            np.save('results/{}/{}_{}_GP_batch{}_{}.npy'.format(dataset_name, dataset_name, BO_method, batch_size, random_seed), Y_train_sele)\n",
    "    else:\n",
    "        if gp_method == 'robust_regression':\n",
    "            np.save('results/{}/{}_{}_RobustGP_batch{}_{}_{}.npy'.format(dataset_name, dataset_name, BO_method, batch_size, acqfn, random_seed), Y_train_sele)\n",
    "        elif gp_method == 'gp_regression':\n",
    "            np.save('results/{}/{}_{}_GP_batch{}_{}_{}.npy'.format(dataset_name, dataset_name, BO_method, batch_size, acqfn, random_seed), Y_train_sele)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run random selection on the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sele_Y, Y_train_sele = list(np.random.choice(Y_test, search_iter, replace = False)), list(Y_train.copy())\n",
    "Y_train_sele.extend(sele_Y)\n",
    "print('Max Y', max(sele_Y))\n",
    "if save_files:\n",
    "    np.save('results/{}/{}_random_{}.npy'.format(dataset_name, dataset_name, random_seed), Y_train_sele)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP of the feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import datashader as ds\n",
    "import datashader.transfer_functions as tf\n",
    "import datashader.bundling as bd\n",
    "import matplotlib.pyplot as plt\n",
    "import colorcet\n",
    "import matplotlib.colors\n",
    "import matplotlib.cm\n",
    "import bokeh.plotting as bpl\n",
    "import bokeh.transform as btr\n",
    "import holoviews as hv\n",
    "import holoviews.operation.datashader as hd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = feature_model.transform(name_sele)\n",
    "X_test = feature_model.transform(name)\n",
    "umap_model = umap.UMAP(densmap=True,dens_lambda=1.0,n_neighbors=10, min_dist=0.2, n_components=2)\n",
    "results = umap_model.fit(X_test)\n",
    "embeddings = umap_model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(embeddings[:, 0], embeddings[:, 1], c=np.log(Y_test)+10, cmap=\"coolwarm\", s=10, alpha = 0.9, marker=\"o\", linewidth=0)\n",
    "plt.xlabel('Dimension 0',fontsize=12)\n",
    "plt.ylabel('Dimension 1',fontsize=12)\n",
    "plt.savefig('results/GB1_2016/umap_GB1_2016.pdf', dpi=2000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
